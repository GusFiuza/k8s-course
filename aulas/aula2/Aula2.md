# Kubernetes B√°sico - Aula 2: Componentes do Kubernetes

---

## üìÖ Objetivos da Aula

- Compreender os principais componentes da arquitetura do Kubernetes
- Diferenciar o que √© Control Plane e o que s√£o os Nodes (trabalho e controle)
- Entender o papel de cada componente no funcionamento do cluster
- Consolidar os conceitos com exemplos visuais e pr√°ticos

---

## ‚úèÔ∏è Resumo Te√≥rico

### Por que o Kubernetes segue uma arquitetura cliente-servidor?

O Kubernetes foi projetado para ser **modular, escal√°vel e distribu√≠do**. Por isso, sua arquitetura √© baseada no modelo **cliente-servidor**, no qual:

- O **servidor** (Control Plane) √© respons√°vel por tomar decis√µes sobre o cluster ‚Äî como agendar pods, gerenciar estado, manter consist√™ncia.
- O **cliente** (como o `kubectl`, CI/CD pipelines ou APIs externas) envia comandos ou consultas para o cluster atrav√©s da **API Server**.

Essa separa√ß√£o permite que **v√°rios clientes interajam simultaneamente com o cluster**, garantindo **controle centralizado e execu√ß√£o distribu√≠da**.

---

### Componentes do Control Plane

1. **kube-apiserver**  
   Porta de entrada do cluster. Valida e processa solicita√ß√µes e exp√µe a API REST do Kubernetes.

2. **etcd**  
   Banco de dados chave-valor que guarda todo o estado desejado do cluster. Altamente dispon√≠vel e distribu√≠do.

3. **kube-scheduler**  
   Decide em qual Node um novo Pod ser√° alocado com base em crit√©rios como CPU, mem√≥ria, afinidades etc.

4. **kube-controller-manager**  
   Conjunto de controladores que garantem que o estado real se aproxime do desejado (ex: ReplicationController, NodeController).

---

### Componentes do Node

1. **kubelet**  
   Agente que roda em cada Node. Se comunica com o API Server e gerencia os Pods.

2. **kube-proxy**  
   Gerencia a rede do cluster. Cria regras de iptables/ipvs para expor Services.

3. **Container Runtime** (ex: containerd, cri-o)  
   Respons√°vel por executar os containers propriamente ditos.

---

## üîÑ Exemplo Detalhado: Como os Componentes do Control Plane Interagem

Vamos supor que voc√™ aplique o seguinte manifesto no seu cluster Kubernetes:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: exemplo-pod
  labels:
     app: exemplo
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    ports:
    - containerPort: 80
```

### O que acontece nos bastidores, passo a passo:

#### 1. `kubectl apply` envia a requisi√ß√£o

- Envia uma requisi√ß√£o HTTP (REST) para o **`kube-apiserver`**.
- O `kube-apiserver` atua como porta de entrada do cluster.

#### 2. `kube-apiserver` valida e registra o Pod

- Valida o manifesto YAML e verifica permiss√µes (RBAC).
- Armazena o objeto Pod no **etcd**.

#### 3. O `kube-scheduler` entra em a√ß√£o

- Monitora Pods sem Node atribu√≠do.
- Avalia recursos dispon√≠veis e regras de agendamento.
- Define o melhor Node e atualiza o Pod via `kube-apiserver`.

#### 4. O `kubelet` do Node escolhido executa o Pod

- Detecta o novo Pod atribu√≠do ao seu Node.
- Puxa a imagem, inicia o container e monitora seu status.

#### 5. O Pod est√° em execu√ß√£o

- O `kubelet` reporta o status ao `kube-apiserver`.
- O estado √© armazenado no etcd e vis√≠vel via `kubectl`.

#### 6. Como o kube-proxy atribui um IP a um Service

Se voc√™ criar um Service para expor esse Pod:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: exemplo-service
spec:
  selector:
    app: exemplo
  ports:
  - port: 80
    targetPort: 80
```

- O `kube-apiserver` valida e salva o objeto Service no `etcd`.
- O `kube-proxy` (em cada Node) monitora os servi√ßos criados e:
  - Gera uma regra de iptables/ipvs para redirecionar o tr√°fego
  - Atribui automaticamente um **ClusterIP** para esse servi√ßo
  - Roteia o tr√°fego para os Pods selecionados pelo `selector`

Voc√™ pode visualizar o IP com:

```bash
kubectl get svc exemplo-service
```

Utilize o comando abaixo para testar a resolu√ß√£o do seu servi√ßo a partir do hostname

```bash
kubectl exec -it exemplo-pod -- curl http://exemplo-service
```

### üîÅ Resumo visual do fluxo dentro do apiserver

```
kubectl apply -f pod.yaml
        ‚îÇ
        ‚ñº
[1] Authentication ‚Üí quem est√° solicitando?
[2] Authorization  ‚Üí pode fazer isso?
[3] Admission      ‚Üí est√° conforme as regras?
        ‚îÇ
        ‚ñº
Se aprovado, √© persistido no etcd e processado pelos controladores
````

- üîê [Authentication - Kubernetes Documentation](https://kubernetes.io/docs/reference/access-authn-authz/authentication/)
- ‚úÖ [Authorization - Kubernetes Documentation](https://kubernetes.io/docs/reference/access-authn-authz/authorization/)
- üß© [Admission Controllers - Kubernetes Documentation](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/)

### üîÅ Resumo visual do fluxo

```
kubectl apply 
      ‚îÇ
      ‚ñº
kube-apiserver (valida e grava no etcd)
      ‚îÇ
      ‚ñº
kube-scheduler (detecta, decide Node, atualiza etcd)
      ‚îÇ
      ‚ñº
kubelet do Node escolhido (executa container)
      ‚îÇ
      ‚ñº
container runtime (roda o nginx)
      ‚îÇ
      ‚ñº
kube-proxy (atribui IP de Service e redireciona tr√°fego)
```

---

## üìò Ilustra√ß√£o da Arquitetura

```
+------------------------+
|     Control Plane      |
|------------------------|
|  kube-apiserver        |
|  etcd                  |
|  kube-scheduler        |
|  kube-controller-mgr   |
+------------------------+
           |
           | (API)
           v
+------------------------+       +------------------------+
|        Node 1          |       |        Node 2          |
|------------------------|       |------------------------|
|  kubelet               |       |  kubelet               |
|  kube-proxy            |       |  kube-proxy            |
|  container runtime     |       |  container runtime     |
|  [Pod A] [Pod B]       |       |  [Pod C] [Pod D]       |
+------------------------+       +------------------------+
```

---

## ‚ùì Perguntas para Reflex√£o

1. O que √© o `kube-apiserver` e por que ele √© considerado o "cora√ß√£o" do cluster?
2. O que o `kube-scheduler` leva em conta para decidir onde rodar um novo Pod?
3. Qual a import√¢ncia do `etcd` para a consist√™ncia do cluster?
4. O que aconteceria se o `kubelet` de um Node falhasse?
5. Por que a separa√ß√£o entre Control Plane e Node √© importante?

---

## üîó Refer√™ncias Oficiais

- https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/
- https://kubernetes.io/docs/concepts/overview/components/
- https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/
- https://etcd.io/docs/
- https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/

---

## üìã Exerc√≠cio Pr√°tico

### Parte 1: Investigue seu cluster

Execute os comandos abaixo e responda:

```bash
kubectl get nodes
kubectl describe node <nome-do-node>
kubectl get componentstatuses
```

**Perguntas:**

- Quantos Nodes est√£o ativos?
- O que cada componente est√° reportando?
- Algum componente est√° em falha?

---

### Parte 2: Simule uma falha de Node

Se estiver usando `minikube`, pare o Node temporariamente:

```bash
minikube stop
```

Ap√≥s alguns segundos, verifique:

```bash
kubectl get nodes
kubectl get pods -A -o wide
```

**Pergunta:**

- O que aconteceu com os Pods que estavam no Node desligado?

---

## üí° Para a pr√≥xima aula

- Estude os objetos mais usados no Kubernetes:
  - `Pod`
  - `ReplicaSet`
  - `Deployment`

- Entenda o conceito de **estado desejado** e o uso de **manifestos YAML** no controle de recursos.

---